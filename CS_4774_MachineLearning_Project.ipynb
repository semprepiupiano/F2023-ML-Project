{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 22:42:27.732652: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-07 22:42:27.876304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 22:42:27.876381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 22:42:27.877830: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 22:42:27.952305: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-07 22:42:27.955115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-07 22:42:29.510538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NUM GPUs Available:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 22:42:32.330789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-11-07 22:42:32.331537: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"NUM GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mW7YFq-r72wa"
      },
      "outputs": [],
      "source": [
        "# data processing\n",
        "# x_train is like past n days, y_train is future n days\n",
        "# past n days will be 365 ? future n days is 7 ? for the week?\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "infile = open('data/aqi_by_county_data/cleaned_aqi_data.pkl', 'rb')\n",
        "aqi_data = pickle.load(infile)\n",
        "full_set = pd.DataFrame(aqi_data['AQI'])\n",
        "training_set = full_set.iloc[:1676, :]\n",
        "test_set = full_set.iloc[1676:, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "n_future = 4 # next 4 days temperature forecast\n",
        "n_past = 30 # Past 30 days\n",
        "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\n",
        "    x_train.append(training_set_scaled[i : i + n_past , 0])\n",
        "    y_train.append(training_set_scaled[i + n_past : i + n_past + n_future , 0 ])\n",
        "x_train , y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXDj6Owm79he"
      },
      "outputs": [],
      "source": [
        "# data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoAwgv_C7_AX"
      },
      "outputs": [],
      "source": [
        "# data standardizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KydzJDoH8Afp"
      },
      "outputs": [],
      "source": [
        "# model: recurrent neural network\n",
        "\n",
        "# x_train and y_train should be numpy arrays\n",
        "\n",
        "# https://medium.com/analytics-vidhya/weather-forecasting-with-recurrent-neural-networks-1eaa057d70c3\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM,Dense ,Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jaN02yet2ssZ",
        "outputId": "c3ce06c7-d790-42f8-91ed-662cbdd97a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 14s 95ms/step - loss: 0.0326 - acc: 0.2678\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0195 - acc: 0.2568\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0191 - acc: 0.2508\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0177 - acc: 0.2489\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0168 - acc: 0.2544\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0168 - acc: 0.2471\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0159 - acc: 0.2635\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0162 - acc: 0.2416\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0153 - acc: 0.2416\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0156 - acc: 0.2368\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0149 - acc: 0.2721\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0150 - acc: 0.2599\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0144 - acc: 0.2495\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0140 - acc: 0.2842\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0140 - acc: 0.2660\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0141 - acc: 0.2575\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0140 - acc: 0.2788\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0137 - acc: 0.2861\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0140 - acc: 0.2903\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0134 - acc: 0.2842\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0137 - acc: 0.2915\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0133 - acc: 0.2751\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0134 - acc: 0.3110\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0130 - acc: 0.2842\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0133 - acc: 0.2855\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0132 - acc: 0.3049\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0130 - acc: 0.3001\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0131 - acc: 0.2879\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0131 - acc: 0.3007\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0130 - acc: 0.2982\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0129 - acc: 0.3256\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0127 - acc: 0.3153\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0126 - acc: 0.3116\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0126 - acc: 0.3128\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0126 - acc: 0.3183\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0125 - acc: 0.3104\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0125 - acc: 0.3153\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0125 - acc: 0.3055\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0125 - acc: 0.3147\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0126 - acc: 0.3268\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0125 - acc: 0.3250\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0123 - acc: 0.3068\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0123 - acc: 0.3244\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0126 - acc: 0.3147\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0124 - acc: 0.3238\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0122 - acc: 0.3451\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0121 - acc: 0.3220\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0124 - acc: 0.3311\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0125 - acc: 0.3372\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 5s 99ms/step - loss: 0.0124 - acc: 0.3372\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0123 - acc: 0.3329\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0124 - acc: 0.3274\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0121 - acc: 0.3177\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0120 - acc: 0.3378\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0121 - acc: 0.3384\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0120 - acc: 0.3262\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0121 - acc: 0.3189\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0121 - acc: 0.3548\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0120 - acc: 0.3427\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0121 - acc: 0.3262\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0120 - acc: 0.3311\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0121 - acc: 0.3214\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0121 - acc: 0.3348\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0120 - acc: 0.3238\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0120 - acc: 0.3414\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0121 - acc: 0.3086\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0119 - acc: 0.3250\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0119 - acc: 0.3457\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0119 - acc: 0.3445\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0119 - acc: 0.3329\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0119 - acc: 0.3402\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0118 - acc: 0.3421\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0120 - acc: 0.3360\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0118 - acc: 0.3177\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0118 - acc: 0.3214\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0118 - acc: 0.3463\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0117 - acc: 0.3281\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0116 - acc: 0.3323\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0118 - acc: 0.3360\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0116 - acc: 0.3457\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0117 - acc: 0.3475\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0117 - acc: 0.3457\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0115 - acc: 0.3220\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0117 - acc: 0.3457\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0115 - acc: 0.3439\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0116 - acc: 0.3335\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0117 - acc: 0.3390\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0115 - acc: 0.3475\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0114 - acc: 0.3378\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0114 - acc: 0.3628\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0113 - acc: 0.3536\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0114 - acc: 0.3177\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0112 - acc: 0.3439\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0113 - acc: 0.3427\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0111 - acc: 0.3439\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0113 - acc: 0.3500\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0111 - acc: 0.3506\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0112 - acc: 0.3384\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0111 - acc: 0.3372\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0113 - acc: 0.3481\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0109 - acc: 0.3506\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0108 - acc: 0.3542\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0108 - acc: 0.3591\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0109 - acc: 0.3536\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0110 - acc: 0.3500\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0111 - acc: 0.3585\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0107 - acc: 0.3615\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0108 - acc: 0.3530\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0107 - acc: 0.3621\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0107 - acc: 0.3591\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0105 - acc: 0.3731\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0106 - acc: 0.3536\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0105 - acc: 0.3475\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0106 - acc: 0.3500\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0105 - acc: 0.3439\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0104 - acc: 0.3488\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0106 - acc: 0.3488\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0104 - acc: 0.3621\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0103 - acc: 0.3481\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0103 - acc: 0.3542\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0102 - acc: 0.3621\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0102 - acc: 0.3518\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0102 - acc: 0.3579\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0102 - acc: 0.3658\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0105 - acc: 0.3481\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0101 - acc: 0.3579\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0102 - acc: 0.3542\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0101 - acc: 0.3628\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0102 - acc: 0.3548\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0100 - acc: 0.3561\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0103 - acc: 0.3500\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0100 - acc: 0.3676\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0100 - acc: 0.3628\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0098 - acc: 0.3597\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0098 - acc: 0.3707\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0100 - acc: 0.3707\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0099 - acc: 0.3603\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0099 - acc: 0.3658\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0103 - acc: 0.3646\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0099 - acc: 0.3743\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0098 - acc: 0.3761\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0097 - acc: 0.3664\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0099 - acc: 0.3591\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0098 - acc: 0.3603\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0097 - acc: 0.3682\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0097 - acc: 0.3652\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0095 - acc: 0.3652\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0096 - acc: 0.3719\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0098 - acc: 0.3615\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0096 - acc: 0.3865\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0095 - acc: 0.3628\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0095 - acc: 0.3628\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0095 - acc: 0.3597\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0096 - acc: 0.3694\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0094 - acc: 0.3682\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0093 - acc: 0.3865\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0094 - acc: 0.3755\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0092 - acc: 0.3670\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0092 - acc: 0.3834\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0093 - acc: 0.3755\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 5s 100ms/step - loss: 0.0092 - acc: 0.3749\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0091 - acc: 0.3676\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0092 - acc: 0.3810\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0091 - acc: 0.3634\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0093 - acc: 0.3792\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0090 - acc: 0.3822\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0089 - acc: 0.3767\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0090 - acc: 0.3707\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0090 - acc: 0.3609\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 5s 99ms/step - loss: 0.0090 - acc: 0.3780\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0090 - acc: 0.3658\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0088 - acc: 0.3725\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0090 - acc: 0.3774\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0089 - acc: 0.3682\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0088 - acc: 0.3749\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0088 - acc: 0.3713\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0089 - acc: 0.3853\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0091 - acc: 0.3755\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0086 - acc: 0.3816\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0087 - acc: 0.3737\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0086 - acc: 0.3822\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0085 - acc: 0.3707\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0086 - acc: 0.3774\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 5s 97ms/step - loss: 0.0086 - acc: 0.3707\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0085 - acc: 0.3798\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 5s 93ms/step - loss: 0.0084 - acc: 0.3786\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0100 - acc: 0.3621\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0087 - acc: 0.3847\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0085 - acc: 0.3810\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0083 - acc: 0.3774\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0083 - acc: 0.3914\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0083 - acc: 0.3877\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0084 - acc: 0.3932\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0085 - acc: 0.3755\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0081 - acc: 0.3901\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0082 - acc: 0.3914\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0084 - acc: 0.3834\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0083 - acc: 0.4029\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0088 - acc: 0.3883\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0081 - acc: 0.3926\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0082 - acc: 0.3774\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0083 - acc: 0.3841\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0083 - acc: 0.3822\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0080 - acc: 0.3713\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0084 - acc: 0.3834\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0082 - acc: 0.3792\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0080 - acc: 0.4017\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0079 - acc: 0.3938\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0079 - acc: 0.3816\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0079 - acc: 0.3974\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0078 - acc: 0.3731\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0081 - acc: 0.3822\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 5s 94ms/step - loss: 0.0080 - acc: 0.3932\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0077 - acc: 0.3962\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0079 - acc: 0.3841\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0077 - acc: 0.3944\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 5s 99ms/step - loss: 0.0077 - acc: 0.3938\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0076 - acc: 0.4127\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 5s 98ms/step - loss: 0.0077 - acc: 0.3920\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0078 - acc: 0.3901\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0077 - acc: 0.3987\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0078 - acc: 0.4005\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0077 - acc: 0.3920\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0075 - acc: 0.3895\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0075 - acc: 0.4023\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0075 - acc: 0.3968\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0074 - acc: 0.3932\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0075 - acc: 0.4011\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0074 - acc: 0.3914\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0075 - acc: 0.3804\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0073 - acc: 0.4121\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0074 - acc: 0.3877\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0074 - acc: 0.3974\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0073 - acc: 0.3920\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0073 - acc: 0.3944\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0071 - acc: 0.4023\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0071 - acc: 0.3974\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0072 - acc: 0.4145\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0074 - acc: 0.3944\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0075 - acc: 0.3920\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0073 - acc: 0.4029\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0073 - acc: 0.4060\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0072 - acc: 0.3877\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0072 - acc: 0.3932\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0074 - acc: 0.4005\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0074 - acc: 0.3987\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0076 - acc: 0.3889\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0072 - acc: 0.4066\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0070 - acc: 0.4121\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0070 - acc: 0.4084\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0069 - acc: 0.4121\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0070 - acc: 0.4206\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0069 - acc: 0.3816\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 5s 90ms/step - loss: 0.0069 - acc: 0.3993\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 5s 95ms/step - loss: 0.0069 - acc: 0.4060\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 5s 96ms/step - loss: 0.0068 - acc: 0.4151\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 5s 92ms/step - loss: 0.0068 - acc: 0.4017\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0066 - acc: 0.4279\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0066 - acc: 0.4054\n",
            "Epoch 260/500\n",
            "49/52 [===========================>..] - ETA: 0s - loss: 0.0070 - acc: 0.4196"
          ]
        }
      ],
      "source": [
        "\n",
        "# set up regressor model\n",
        "regressor = Sequential()\n",
        "regressor.add(Bidirectional(LSTM(units=30, return_sequences=True, input_shape = (x_train.shape[1],1) ) ))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(LSTM(units= 30))\n",
        "regressor.add(Dropout(0.2))\n",
        "regressor.add(Dense(units = n_future,activation='linear'))\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc']) # adam optimizer for optimal efficiency\n",
        "regressor.fit(x_train, y_train, epochs=500,batch_size=32 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pj9L_rAAcWQO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "[[23.847404]\n",
            " [21.79368 ]\n",
            " [19.517614]\n",
            " [21.689926]]\n"
          ]
        }
      ],
      "source": [
        "# read test dataset\n",
        "test_set_scaled = sc.transform(test_set)\n",
        "testdataset = test_set_scaled\n",
        "real_temperature = test_set_scaled\n",
        "testing = sc.transform(testdataset)\n",
        "testing = np.array(testing)\n",
        "testing = np.reshape(testing,(testing.shape[1],testing.shape[0],1))\n",
        "\n",
        "# predict model\n",
        "predicted_temperature = regressor.predict(testing)\n",
        "predicted_temperature = sc.inverse_transform(predicted_temperature)\n",
        "predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))\n",
        "\n",
        "print(predicted_temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "n_future = 4 # next 4 days temperature forecast\n",
        "n_past = 30 # Past 30 days\n",
        "for i in range(0,len(test_set_scaled)-n_past-n_future+1):\n",
        "    x_test.append(test_set_scaled[i : i + n_past , 0])\n",
        "    y_test.append(test_set_scaled[i + n_past : i + n_past + n_future , 0 ])\n",
        "\n",
        "x_test , y_test = np.array(x_test), np.array(y_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0] , x_test.shape[1], 1) )\n",
        "\n",
        "predictions = regressor.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = np.mean(np.square(predictions - y_test))\n",
        "print(\"Mean Squared Error: \", mse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
